# è¯„ä»·é¡¹ç›®

# æ¨¡å—åŠå®ç°

### é¡¹ç›®æ¡†æ¶æ­å»º

1. åˆ›å»ºé¡¹ç›®
    
    ```go
    kratos new review-service
    ```
    
2. æ·»åŠ proto
    
    ```go
    kratos proto add api/review/v1/review.proto
    ```
    
3. ç”Ÿæˆå®¢æˆ·ç«¯ä»£ç 
    
    ```go
    kratos proto client api/review/v1/review.proto
    ```
    
4. ç”ŸæˆæœåŠ¡ç«¯ä»£ç 
    
    ```go
    kratos proto server api/review/v1/review.proto -t internal/service
    ```
    

### é¡¹ç›®ä¾èµ–å‡†å¤‡

1. Mysqlç¯å¢ƒï¼ˆdockerï¼‰
2. Redisç¯å¢ƒï¼ˆdockerï¼‰
3. å»ºç«‹æ•°æ®åº“è¡¨
4. ä¿®æ”¹configé…ç½®æ–‡ä»¶ mysqlï¼Œredis 
    
    ```go
    make config
    ```
    

## å¼€å‘æ¥å£æµç¨‹

1. å®šä¹‰apiæ–‡ä»¶
    
    æ ¹æ®éœ€æ±‚ç¼–å†™apiæ–‡ä»¶
    
2. ç”Ÿæˆå®¢æˆ·ç«¯å’ŒæœåŠ¡ç«¯ä»£ç 
    
    ```go
    make api 
    ```
    
3. å¡«å……ä¸šåŠ¡é€»è¾‘
    
    ./internal
    
    server â†’ service â†’ biz â†’ data
    
4. æ›´æ–°ä¾èµ–æ³¨å…¥

## ä¸šåŠ¡å¼€å‘

### è¯„è®ºæœåŠ¡

1. åˆ›å»ºè¯„è®º
    1. é›ªèŠ±ç®—æ³•ç”ŸæˆID
    2. validateå‚æ•°æ ¡éªŒ
        1. ä¸‹è½½æ’ä»¶
        2. åœ¨apiä¸­çš„pbæ–‡ä»¶ç¼–å†™ æ ¡éªŒè§„åˆ™
        3. ç”Ÿæˆä»£ç 
        4. æ³¨å†Œå‚æ•°ä¸­é—´ä»¶
        
        ```go
        // ä¸‹è½½æ’ä»¶
        go install github.com/envoyproxy/protoc-gen-validate@latest
        
        // å¯¼å…¥
        import "validate/validate.proto";
        
        // ç”Ÿæˆä»£ç 
        make validate
        .PHONY: validate
        # generate validate proto
        validate:
        	protoc --proto_path=. \
                   --proto_path=./third_party \
                   --go_out=paths=source_relative:. \
                   --validate_out=paths=source_relative,lang=go:. \
                   $(API_PROTO_FILES)
        
                   
        //ä¸­é—´ä»¶ server
        		http.Middleware(
        			recovery.Recovery(),
        			validate.Validator(),
        		),
        	}
        			grpc.Middleware(
        			recovery.Recovery(),
        			validate.Validator(),
        		),
        	}
        ```
        
2. é”™è¯¯å¤„ç†
    1. å®šä¹‰protoæ–‡ä»¶
    2. ç”Ÿæˆä»£ç 
    3. ä¸šåŠ¡ä¸­ä½¿ç”¨ç”Ÿæˆçš„é”™è¯¯ä»£ç è¿”å›
    
    ```go
    // å®‰è£…
    go install github.com/go-kratos/kratos/cmd/protoc-gen-go-errors/v2@latest
    
    protoc --proto_path=. \
             --proto_path=./third_party \
             --go_out=paths=source_relative:. \
             --go-errors_out=paths=source_relative:. \
             $(API_PROTO_FILES)
             
    // æˆ–è€…
    make errors
    ```
    
3. è¯„ä»·è¯¦æƒ…
4. å®¡æ ¸è¯„ä»·
5. ç”³è¯‰è¯„ä»·
    
    ```go
    r.data.query.ReviewAppealInfo.
    		WithContext(ctx).
    		Clauses(clause.OnConflict{
    			Columns: []clause.Column{
    				{Name: "review_id"}, // ON DUPLICATE KEY
    			},
    			DoUpdates: clause.Assignments(map[string]interface{}{ // UPDATE
    				"status":     10,
    				"content":    appeal.Content,
    				"reason":     appeal.Reason,
    				"pic_info":   appeal.PicInfo,
    				"video_info": appeal.VideoInfo,
    			}),
    		}).
    		Create(appeal) // INSERT
    		å½“å­˜åœ¨æ—¶å°±æ›´æ–°ï¼Œå½“ä¸å­˜åœ¨æ˜¯å°±åˆ›å»º
    		
    		INSERT INTO `table` *** ON DUPLICATE KEY UPDATE ***;
    ```
    
6. å›å¤è¯„ä»·
    1. review-service æ–°å¢grpcè°ƒç”¨
        1. gorm-genäº‹åŠ¡æ“ä½œ
            
            ```go
            r.data.query.Transaction(func(tx *query.Query) error {
            		// å›å¤ä¸€æ¡æ’å…¥æ•°æ®
            		if err := tx.ReviewReplyInfo.WithContext(ctx).Save(reply); err != nil {
            			r.log.WithContext(ctx).Errorf("SaveReply create reply fail, err:%v", err)
            			return err
            		}
            		// è¯„ä»·è¡¨æ›´æ–°hasReplyå­—æ®µ\
            		if _, err := tx.ReviewInfo.WithContext(ctx).Where(tx.ReviewInfo.ReviewID.Eq(review.ReviewID)).Update(tx.ReviewInfo.HasReply, 1); err != nil {
            			r.log.WithContext(ctx).Errorf("SaveReply update reply fail, err:%v", err)
            			return err
            		}
            		return nil
            	})
            ```
            
        2. é˜²æ­¢æ°´å¹³è¶Šæƒ
            
            ```go
            if review.StoreID != reply.StoreID {
            		return nil, errors.New("æ°´å¹³è¶Šæƒ")
            	}
            ```
            
7. è¯„ä»·åˆ—è¡¨

### è¯„ä»·æœåŠ¡cç«¯

1. å‘è¡¨è¯„ä»·
2. æŸ¥çœ‹è¯„ä»·
3. æŸ¥çœ‹è‡ªå·±çš„è¯„ä»·

### è¯„ä»·bç«¯

1. åº—é“ºè¯„ä»·åˆ—è¡¨
2. åº—é“ºè¯„ä»·è¯¦æƒ…
3. å›å¤è¯„ä»·
4. ç”³è¯‰è¯„ä»·

### è¯„ä»·oç«¯

1. è¯„ä»·åˆ—è¡¨ï¼ˆç­›é€‰ï¼‰
2. è¯„ä»·è¯¦æƒ…
3. è¯„ä»·å®¡æ ¸
4. è¯„ä»·ç”³è¯‰

**å…³é”®ç‚¹**

é›ªèŠ±ç®—æ³•â½£æˆID

validateå‚æ•°æ ¡éªŒ

GORMäº‹åŠ¡æ“ä½œ

æ¥â¼å¹‚ç­‰

æ¥â¼é˜²â½Œâ½”å¹³è¶Šæƒ

## go submodule

é¡¹â½¬ä¸­å¦‚ä½•ç®¡ç†pbâ½‚ä»¶
protoâ½‚ä»¶è¦â½¤â¼€ä¸ª
protocè¦ä½¿â½¤åŒâ¼€ä¸ªç‰ˆæœ¬
é€šå¸¸åœ¨å…¬å¸ä¸­éƒ½æ˜¯æŠŠ proto â½‚ä»¶å’Œâ½£æˆçš„ä¸åŒè¯­â¾”çš„ä»£ç éƒ½æ”¾åœ¨â¼€ä¸ªå•ç‹¬çš„å…¬â½¤ä»£ç åº“ä¸­ã€‚
åˆ«çš„é¡¹â½¬ç›´æ¥å¼•â½¤è¿™ä¸ªå…¬â½¤ä»£ç åº“ã€‚

è¯­æ³•ï¼šgitâ¼¦æ¨¡å—
é¡¹â½¬ä¸­æ·»åŠ â¼¦æ¨¡å—ã€‚å°† [git@github.com](mailto:git@github.com):Q1mi/reviewapis.git ä½œä¸ºå½“å‰é¡¹â½¬çš„â¼¦â½¬å½•ï¼Œâ½¬å½•åä¸º api 

```go
git submodule add git@xxxxxxx /api
```

å½“å‰â½¬å½•ä¸‹ä¼šå¤šâ¼€ä¸ª .gitmodules â½‚ä»¶

```go
# â½¤æ¥åˆå§‹åŒ–æœ¬åœ°é…ç½®â½‚ä»¶
git submodule init
# ä»è¯¥é¡¹â½¬ä¸­æŠ“å–æ‰€æœ‰æ•°æ®å¹¶æ£€å‡ºâ½—é¡¹â½¬ä¸­åˆ—å‡ºçš„åˆé€‚çš„æäº¤ã€‚
git submodule update
```

## æœåŠ¡æ³¨å†Œä¸æœåŠ¡å‘ç°

1. consulæ³¨å†Œä¸­å¿ƒ
    1. internal/conf/xx.proto
    2. configs/xx.yaml

```go
message Registry{
  message Consul{
    string address = 1;
    string scheme = 2;
  }
  Consul consul = 1;
}

consul:
  address: 127.0.0.1:8500
  scheme: http
  
 make config
```

1. serviceæ·»åŠ æœåŠ¡æ³¨å†Œ
    1. æ³¨å†Œçš„æ—¶æœº --> internal/serverå±‚ --> æä¾›æ„é€ å‡½æ•°--> wireæ³¨â¼Š
    2. mainå‡½æ•°ä¼ â¼Šconf.Registryé…ç½®
    3. æŒ‡å®šåº”â½¤ç¨‹åºçš„nameå’Œversionï¼Œåœ¨æ³¨å†Œæ—¶ä½¿â½¤

```go
// server
func NewRegistrar(cfg *conf.Registry) registry.Registrar {
	// new consul client
	c := api.DefaultConfig()
	c.Address = cfg.Consul.Address
	c.Scheme = cfg.Consul.Scheme
	client, err := api.NewClient(c)
	if err != nil {
		panic(err)
	}
	// new reg with consul client
	reg := consul.New(client, consul.WithHealthCheck(true))
	return reg
}

var ProviderSet = wire.NewSet(NewRegistrar, NewGRPCServer, NewHTTPServer)

// mian.go
func newApp(logger log.Logger, r registry.Registrar, gs *grpc.Server, hs *http.Server) *kratos.App {
	return kratos.New(
		kratos.ID(id),
		kratos.Name(Name),
		kratos.Version(Version),
		kratos.Metadata(map[string]string{}),
		kratos.Logger(logger),
		kratos.Server(
			gs,
			hs,
		),
		kratos.Registrar(r),
	)
}

var (
	// Name is the name of the compiled software.
	Name string =  "review.service"
	// Version is the version of the compiled software.
	Version string = "v0.1"
	// flagconf is the config flag.
	flagconf string

	id, _ = os.Hostname()
)

// è§£æregistry.yamlä¸­çš„é…ç½®
	var rc conf.Registry
	if err := c.Scan(&rc); err != nil {
		panic(err)
	}

	app, cleanup, err := wireApp(bc.Server, &rc, bc.Data, logger)
	
// wire.go
func wireApp(*conf.Server, *conf.Registry, *conf.Data, log.Logger) (*kratos.App, func(), error) {
	panic(wire.Build(server.ProviderSet, data.ProviderSet, biz.ProviderSet, service.ProviderSet, newApp))
}

cd cmd/review -> wire
```

1. review-bæ·»åŠ æœåŠ¡å‘ç°æµç¨‹\
    1. æœåŠ¡å‘ç°çš„æ—¶æœº --> internal/data å±‚ --> æä¾›æ„é€ å‡½æ•° --> wireæ³¨â¼Š
    2. mainå‡½æ•°ä¼ â¼Šconf.Registryé…ç½®

```go
registry:
  consul:
    address: 127.0.0.1:8500
    scheme: http
  
  message Bootstrap {
  Server server = 1;
  Data data = 2;
  Registry registry = 3;
}

message Registry {
  message Consul {
    string address = 1;
    string scheme = 2;
  }
  Consul consul = 1;
}

// data.go 
func NewDiscovever(conf *conf.Registry) registry.Discovery{
	// new consul client
	c := api.DefaultConfig()
	c.Address = conf.Consul.Address
	c.Scheme = conf.Consul.Scheme
	client, err := api.NewClient(c)
	if err != nil {
		panic(err)
	}
	// new dis with consul client
	dis := consul.New(client)
	return dis
}

func NewReviewServiceClient(d registry.Discovery) v1.ReviewClient {
	endpoint := "discovery:///review.service"
	conn, err := grpc.DialInsecure(context.Background(),
		// grpc.WithEndpoint("127.0.0.1:9001"),
		grpc.WithEndpoint(endpoint),
		grpc.WithDiscovery(d),
		grpc.WithMiddleware(
			recovery.Recovery(),
			validate.Validator(),
		))
	if err != nil {
		panic(err)
	}
	return v1.NewReviewClient(conn)
}

// ProviderSet is data providers.
var ProviderSet = wire.NewSet(NewData, NewBusinessRepo, NewReviewServiceClient, NewDiscovever)

// main.go
app, cleanup, err := wireApp(bc.Server, bc.Registry, bc.Data, logger)
	if err != nil {
		panic(err)
	}
	defer cleanup()
	
// wire.go 
func wireApp(*conf.Server, *conf.Registry, *conf.Data, log.Logger) (*kratos.App, func(), error) {
	panic(wire.Build(server.ProviderSet, data.ProviderSet, biz.ProviderSet, service.ProviderSet, newApp))
}

cd cmd/service-b -> wire
```

## canal

Canal æ˜¯é˜¿é‡Œå¼€æºçš„ä¸€æ¬¾ MySQL æ•°æ®åº“å¢é‡æ—¥å¿—è§£æå·¥å…·ï¼Œæä¾›å¢é‡æ•°æ®è®¢é˜…å’Œæ¶ˆè´¹ã€‚ä½¿ç”¨Canalèƒ½å¤Ÿå®ç°å¼‚æ­¥æ›´æ–°æ•°æ®ï¼Œé…åˆMQä½¿ç”¨å¯åœ¨å¾ˆå¤šä¸šåŠ¡åœºæ™¯ä¸‹å‘æŒ¥å·¨å¤§ä½œç”¨ã€‚

1. **å·¥ä½œåŸç†**
    
    **MySQLä¸»å¤‡å¤åˆ¶åŸç†**
    
    - MySQL master å°†æ•°æ®å˜æ›´å†™å…¥äºŒè¿›åˆ¶æ—¥å¿—ï¼ˆbinary logï¼‰, æ—¥å¿—ä¸­çš„è®°å½•å«åšäºŒè¿›åˆ¶æ—¥å¿—äº‹ä»¶ï¼ˆbinary log eventsï¼Œå¯ä»¥é€šè¿‡ show binlog events è¿›è¡ŒæŸ¥çœ‹ï¼‰
    - MySQL slave å°† master çš„ binary log events æ‹·è´åˆ°å®ƒçš„ä¸­ç»§æ—¥å¿—(relay log)
    - MySQL slave é‡æ”¾ relay log ä¸­äº‹ä»¶ï¼Œå°†æ•°æ®å˜æ›´åæ˜ åˆ°å®ƒè‡ªå·±çš„æ•°æ®
    
    **Canal å·¥ä½œåŸç†**
    
    - Canal æ¨¡æ‹Ÿ MySQL slave çš„äº¤äº’åè®®ï¼Œä¼ªè£…è‡ªå·±ä¸º MySQL slave ï¼Œå‘ MySQL master å‘é€ dump åè®®
    - MySQL master æ”¶åˆ° dump è¯·æ±‚ï¼Œå¼€å§‹æ¨é€ binary log ç»™ slave (å³ Canal )
    - Canal è§£æ binary log å¯¹è±¡(åŸå§‹ä¸º byte æµ)
2. **ç¯å¢ƒå‡†å¤‡**
    1. MySQLç¯å¢ƒ
        1. **å¼€å¯binlog**
        2. my.cnf,ä¿®æ”¹é…ç½®æ–‡ä»¶ä¹‹åï¼Œé‡å¯MySQLã€‚
            
            ```go
            /etc/mysql/my.cnf
            [mysqld]
            log-bin=mysql-bin # å¼€å¯ binlog
            binlog-format=ROW # é€‰æ‹© ROW æ¨¡å¼
            server_id=1 # é…ç½® MySQL replaction éœ€è¦å®šä¹‰ï¼Œä¸è¦å’Œ canal çš„ slaveId é‡å¤
            
            //æŸ¥çœ‹
            show variables like 'log_bin'; -> on
            show variables like 'binlog_format'; -> row
            
            ```
            
        3. **æ·»åŠ æˆæƒ**
            
            ```go
            CREATE USER canan(name) IDENTIFIED BY 'password';  // æŒ‰éœ€å¡«å†™nameå’Œpassword
            GRANT SELECT, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'canal'@'%';
            -- GRANT ALL PRIVILEGES ON *.* TO 'canal'@'%' ;
            FLUSH PRIVILEGES;
            
            ```
            
    2. **å®‰è£…Canal**
        
        docker:
        
        ```go
        docker pull canal/canal-server:latest
        
        // å¯åŠ¨å®¹å™¨
        docker run -d \
          --name canal-server \
          --add-host=host.docker.internal:host-gateway \
          canal/canal-server:latest
        
        // è¿›å…¥å®¹å™¨
        docker exec -it canal-server /bin/bash
        
        // ä¿®è¯¥é…ç½®
        vi canal-server/conf/example/instance.properties
        
        canal.instance.master.address=host.docker.internal:3306
        
        canal.instance.tsdb.dbUsername=canal
        canal.instance.tsdb.dbPassword=password // ä¸Šé¢çš„nameå’Œpassword
        ```
        

## kafka

Kafkaæ˜¯ä¸€ç§é«˜ååé‡çš„åˆ†å¸ƒå¼å‘å¸ƒè®¢é˜…æ¶ˆæ¯ç³»ç»Ÿ

Apache Kafkaæ˜¯â¼€ä¸ªå¼€æºçš„åˆ†å¸ƒå¼æµç³»ç»Ÿï¼Œè¯¥é¡¹â½¬æ—¨åœ¨æä¾›â¼€ä¸ªç»Ÿâ¼€çš„ã€â¾¼ååé‡ã€ä½å»¶è¿Ÿçš„å¹³å°ï¼Œâ½¤äºå¤„ç†å®æ—¶æ•°æ®æµã€‚å®ƒå…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š
â½€æŒæ¶ˆæ¯çš„å‘å¸ƒå’Œè®¢é˜…ï¼Œç±»ä¼¼äº RabbtMQã€RocketMQ ç­‰æ¶ˆæ¯é˜Ÿåˆ—ï¼›
â½€æŒæ•°æ®å®æ—¶å¤„ç†ï¼›
èƒ½ä¿è¯æ¶ˆæ¯çš„å¯é æ€§æŠ•é€’ï¼›
â½€æŒæ¶ˆæ¯çš„æŒä¹…åŒ–å­˜å‚¨ï¼Œå¹¶é€šè¿‡å¤šå‰¯æœ¬åˆ†å¸ƒå¼çš„å­˜å‚¨â½…æ¡ˆæ¥ä¿è¯æ¶ˆæ¯çš„å®¹é”™ï¼›

â¾¼ååç‡ï¼Œå• Broker å¯ä»¥è½»æ¾å¤„ç†æ•°åƒä¸ªåˆ†åŒºä»¥åŠæ¯ç§’ç™¾ä¸‡çº§çš„æ¶ˆæ¯é‡ã€‚

Kafkaæ˜¯â¼€ä¸ªæ•°æ®æµç³»ç»Ÿï¼Œå…è®¸å¼€å‘â¼ˆå‘˜åœ¨æ–°äº‹ä»¶å‘â½£æ—¶å®æ—¶åšå‡ºååº”ã€‚Kafkaä½“ç³»ç»“æ„ç”±å­˜å‚¨å±‚å’Œè®¡ç®—å±‚ç»„æˆã€‚å­˜
å‚¨å±‚æ—¨åœ¨â¾¼æ•ˆåœ°å­˜å‚¨æ•°æ®ï¼Œæ˜¯â¼€ä¸ªåˆ†å¸ƒå¼ç³»ç»Ÿï¼Œå¯ä»¥è½»æ¾åœ°æ‰©å±•ç³»ç»Ÿä»¥é€‚åº”å¢â»“ã€‚
è®¡ç®—å±‚ç”±å››ä¸ªæ ¸â¼¼ç»„ä»¶ç»„æˆâ€”â€”â½£äº§è€…ã€æ¶ˆè´¹è€…ã€æµå’Œè¿æ¥å™¨APIï¼Œå®ƒä»¬å…è®¸Kafkaåœ¨åˆ†å¸ƒå¼ç³»ç»Ÿä¸­æ‰©å±•åº”â½¤ç¨‹åºã€‚

1. â½£äº§è€…ï¼ˆProducerï¼‰
2. æ¶ˆè´¹è€…ï¼ˆConsumerï¼‰
3. æµå¤„ç†ï¼ˆStreamsï¼‰
4. è¿æ¥å™¨ï¼ˆConnectorsï¼‰APIs

**ç›¸å…³æœ¯è¯­**

Messages And Batchesï¼šKafka çš„åŸºæœ¬æ•°æ®å•å…ƒè¢«ç§°ä¸º message(æ¶ˆæ¯)ï¼Œä¸ºå‡å°‘â½¹ç»œå¼€é”€ï¼Œæâ¾¼æ•ˆç‡ï¼Œå¤šä¸ª

æ¶ˆæ¯ä¼šè¢«æ”¾â¼ŠåŒâ¼€æ‰¹æ¬¡ (Batch) ä¸­åå†å†™â¼Šã€‚

Topicï¼šâ½¤æ¥å¯¹æ¶ˆæ¯è¿›â¾åˆ†ç±»ï¼Œæ¯ä¸ªè¿›â¼Šåˆ°Kafkaçš„ä¿¡æ¯éƒ½ä¼šè¢«æ”¾åˆ°â¼€ä¸ªTopicä¸‹

Brokerï¼šâ½¤æ¥å®ç°æ•°æ®å­˜å‚¨çš„ä¸»æœºæœåŠ¡å™¨,kafkaèŠ‚ç‚¹

Partitionï¼šæ¯ä¸ªTopicä¸­çš„æ¶ˆæ¯ä¼šè¢«åˆ†ä¸ºè‹¥â¼²ä¸ªPartitionï¼Œä»¥æâ¾¼æ¶ˆæ¯çš„å¤„ç†æ•ˆç‡

Producerï¼šæ¶ˆæ¯çš„â½£äº§è€…Consumerï¼šæ¶ˆæ¯çš„æ¶ˆè´¹è€…

Consumer Groupï¼šæ¶ˆæ¯çš„æ¶ˆè´¹ç¾¤ç»„

Kafka çš„æ¶ˆæ¯é€šè¿‡ Topics(ä¸»é¢˜) è¿›â¾åˆ†ç±»ï¼Œâ¼€ä¸ªä¸»é¢˜å¯ä»¥è¢«åˆ†ä¸ºè‹¥â¼²ä¸ª Partitions(åˆ†åŒº)ï¼Œâ¼€ä¸ªåˆ†åŒºå°±æ˜¯â¼€ä¸ªæäº¤â½‡å¿— (commit log)ã€‚æ¶ˆæ¯ä»¥è¿½åŠ çš„â½…å¼å†™â¼Šåˆ†åŒºï¼Œç„¶åä»¥å…ˆâ¼Šå…ˆå‡ºçš„é¡ºåºè¯»å–ã€‚Kafka é€šè¿‡åˆ†åŒºæ¥å®ç°æ•°æ®çš„å†—ä½™å’Œä¼¸ç¼©æ€§ï¼Œåˆ†åŒºå¯ä»¥åˆ†å¸ƒåœ¨ä¸åŒçš„æœåŠ¡å™¨ä¸Šï¼Œè¿™æ„å‘³ç€â¼€ä¸ª Topic å¯ä»¥æ¨ªè·¨å¤šä¸ªæœåŠ¡å™¨ï¼Œä»¥æä¾›â½å•ä¸ªæœåŠ¡å™¨æ›´å¼ºâ¼¤çš„æ€§èƒ½ã€‚ç”±äºâ¼€ä¸ª Topic åŒ…å«å¤šä¸ªåˆ†åŒºï¼Œå› æ­¤â½†æ³•åœ¨æ•´ä¸ª Topic èŒƒå›´å†…ä¿è¯æ¶ˆæ¯çš„é¡ºåºæ€§ï¼Œä½†å¯ä»¥ä¿è¯æ¶ˆæ¯åœ¨å•ä¸ªåˆ†åŒºå†…çš„é¡ºåºæ€§ã€‚

ä¸ºäº†åˆ†æ•£ä¸»é¢˜ä¸­äº‹ä»¶çš„å­˜å‚¨å’Œå¤„ç†ï¼ŒKafkaä½¿â½¤äº†åˆ†åŒºçš„æ¦‚å¿µã€‚â¼€ä¸ªä¸»é¢˜ç”±â¼€ä¸ªæˆ–å¤šä¸ªåˆ†åŒºç»„æˆï¼Œè¿™äº›åˆ†åŒºå¯ä»¥ä½äºKafkaé›†ç¾¤ä¸­çš„ä¸åŒèŠ‚ç‚¹ä¸Šã€‚æ¯ä¸ªåˆ†åŒºéƒ½æ˜¯â¼€ä¸ªæœ‰åºçš„ï¼Œä¸å¯å˜çš„è®°å½•åºåˆ—ï¼Œä¸æ–­é™„åŠ åˆ°ç»“æ„åŒ–çš„æäº¤â½‡å¿—ä¸­ã€‚åˆ†åŒºä¸­çš„è®°å½•æ¯éƒ½åˆ†é…äº†â¼€ä¸ªç§°ä¸ºåç§»çš„é¡ºåºIDå·ï¼Œå®ƒå”¯â¼€åœ°æ ‡è¯†åˆ†åŒºä¸­çš„æ¯ä¸ªè®°å½•ã€‚Kafkaé›†ç¾¤â½€æŒæŒ‰é…ç½®æŒä¹…åŒ–ä¿å­˜æ‰€æœ‰å·²å‘å¸ƒçš„è®°å½•ã€‚ä¾‹å¦‚ï¼Œå¦‚æœä¿ç•™ç­–ç•¥è®¾ç½®ä¸ºä¸¤å¤©ï¼Œåˆ™åœ¨å‘å¸ƒè®°å½•åçš„ä¸¤å¤©å†…ï¼Œå®ƒå¯ä¾›æ¶ˆè´¹ï¼Œä¹‹åå°†è¢«ä¸¢å¼ƒä»¥é‡Šæ”¾ç©ºé—´ã€‚

**â½£äº§è€…**

â½£äº§è€…è´Ÿè´£åˆ›å»ºæ¶ˆæ¯ã€‚â¼€èˆ¬æƒ…å†µä¸‹ï¼Œâ½£äº§è€…åœ¨æŠŠæ¶ˆæ¯å‡è¡¡åœ°åˆ†å¸ƒåˆ°åœ¨ä¸»é¢˜çš„æ‰€æœ‰åˆ†åŒºä¸Šï¼Œâ½½å¹¶ä¸å…³â¼¼æ¶ˆæ¯ä¼šè¢«å†™åˆ°å“ªä¸ªåˆ†åŒºã€‚å¦‚æœæˆ‘ä»¬æƒ³è¦æŠŠæ¶ˆæ¯å†™åˆ°æŒ‡å®šçš„åˆ†åŒºï¼Œå¯ä»¥é€šè¿‡â¾ƒå®šä¹‰åˆ†åŒºå™¨æ¥å®ç°ã€‚

æ¶ˆè´¹è€…æ˜¯æ¶ˆè´¹è€…ç¾¤ç»„çš„â¼€éƒ¨åˆ†ï¼Œæ¶ˆè´¹è€…è´Ÿè´£æ¶ˆè´¹æ¶ˆæ¯ã€‚æ¶ˆè´¹è€…å¯ä»¥è®¢é˜…â¼€ä¸ªæˆ–è€…å¤šä¸ªä¸»é¢˜ï¼Œå¹¶æŒ‰ç…§æ¶ˆæ¯â½£æˆçš„é¡ºåºæ¥è¯»å–å®ƒä»¬ã€‚æ¶ˆè´¹è€…é€šè¿‡æ£€æŸ¥æ¶ˆæ¯çš„åç§»é‡ (offset) æ¥åŒºåˆ†è¯»å–è¿‡çš„æ¶ˆæ¯ã€‚åç§»é‡æ˜¯â¼€ä¸ªä¸æ–­é€’å¢çš„æ•°å€¼ï¼Œåœ¨åˆ›å»ºæ¶ˆæ¯æ—¶ï¼ŒKafka ä¼šæŠŠå®ƒæ·»åŠ åˆ°å…¶ä¸­ï¼Œåœ¨ç»™å®šçš„åˆ†åŒºâ¾¥ï¼Œæ¯ä¸ªæ¶ˆæ¯çš„åç§»é‡éƒ½æ˜¯å”¯â¼€çš„ã€‚æ¶ˆè´¹è€…æŠŠæ¯ä¸ªåˆ†åŒºæœ€åè¯»å–çš„åç§»é‡ä¿å­˜åœ¨ Zookeeper æˆ– Kafka ä¸Šï¼Œå¦‚æœæ¶ˆè´¹è€…å…³é—­æˆ–è€…é‡å¯ï¼Œå®ƒè¿˜å¯ä»¥é‡æ–°è·å–è¯¥åç§»é‡ï¼Œä»¥ä¿è¯è¯»å–çŠ¶æ€ä¸ä¼šä¸¢å¤±ã€‚

â¼€ä¸ªåˆ†åŒºåªèƒ½è¢«åŒâ¼€ä¸ªæ¶ˆè´¹è€…ç¾¤ç»„â¾¥â¾¯çš„â¼€ä¸ªæ¶ˆè´¹è€…è¯»å–ï¼Œä½†å¯ä»¥è¢«ä¸åŒæ¶ˆè´¹è€…ç¾¤ç»„ä¸­æ‰€ç»„æˆçš„å¤šä¸ªæ¶ˆè´¹è€…å…±åŒè¯»å–ã€‚å¤šä¸ªæ¶ˆè´¹è€…ç¾¤ç»„ä¸­æ¶ˆè´¹è€…å…±åŒè¯»å–åŒâ¼€ä¸ªä¸»é¢˜æ—¶ï¼Œå½¼æ­¤ä¹‹é—´äº’ä¸å½±å“ã€‚

â¼€ä¸ªç‹¬â½´çš„ Kafka æœåŠ¡å™¨è¢«ç§°ä¸º Brokerã€‚Broker æ¥æ”¶æ¥â¾ƒâ½£äº§è€…çš„æ¶ˆæ¯ï¼Œä¸ºæ¶ˆæ¯è®¾ç½®åç§»é‡ï¼Œå¹¶æäº¤æ¶ˆæ¯åˆ°ç£ç›˜ä¿å­˜ã€‚Broker ä¸ºæ¶ˆè´¹è€…æä¾›æœåŠ¡ï¼Œå¯¹è¯»å–åˆ†åŒºçš„è¯·æ±‚åšå‡ºå“åº”ï¼Œè¿”å›å·²ç»æäº¤åˆ°ç£ç›˜çš„æ¶ˆæ¯ã€‚Broker æ˜¯é›†ç¾¤ (Cluster) çš„ç»„æˆéƒ¨åˆ†ã€‚æ¯â¼€ä¸ªé›†ç¾¤éƒ½ä¼šé€‰ä¸¾å‡ºâ¼€ä¸ª Broker ä½œä¸ºé›†ç¾¤æ§åˆ¶å™¨ (Controller)ï¼Œé›†ç¾¤æ§åˆ¶å™¨è´Ÿè´£ç®¡ç†â¼¯ä½œï¼ŒåŒ…æ‹¬å°†åˆ†åŒºåˆ†é…ç»™ Broker å’Œç›‘æ§ Brokerã€‚
åœ¨é›†ç¾¤ä¸­ï¼Œâ¼€ä¸ªåˆ†åŒº (Partition) ä»å±â¼€ä¸ª Brokerï¼Œè¯¥ Broker è¢«ç§°ä¸ºåˆ†åŒºçš„â¾¸é¢† (Leader)ã€‚â¼€ä¸ªåˆ†åŒºå¯ä»¥åˆ†é…ç»™å¤šä¸ª Brokersï¼Œè¿™ä¸ªæ—¶å€™ä¼šå‘â½£åˆ†åŒºå¤åˆ¶ã€‚è¿™ç§å¤åˆ¶æœºåˆ¶ä¸ºåˆ†åŒºæä¾›äº†æ¶ˆæ¯å†—ä½™ï¼Œå¦‚æœæœ‰â¼€ä¸ª Broker å¤±æ•ˆï¼Œå…¶ä»–
Broker å¯ä»¥æ¥ç®¡é¢†å¯¼æƒã€‚

1. ç¯å¢ƒå‡†å¤‡
    
    ```go
    // docker-compose.yml
    version: '2.1'
    
    services:
      zoo1:
        image: confluentinc/cp-zookeeper:7.3.2
        hostname: zoo1
        container_name: zoo1
        ports:
          - "2181:2181"
        environment:
          ZOOKEEPER_CLIENT_PORT: 2181
          ZOOKEEPER_SERVER_ID: 1
          ZOOKEEPER_SERVERS: zoo1:2888:3888
    
      kafka1:
        image: confluentinc/cp-kafka:7.3.2
        hostname: kafka1
        container_name: kafka1
        ports:
          - "9092:9092"
          - "29092:29092"
          - "9999:9999"
        environment:
          KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka1:19092,EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9092,DOCKER://host.docker.internal:29092
          KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,DOCKER:PLAINTEXT
          KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
          KAFKA_ZOOKEEPER_CONNECT: "zoo1:2181"
          KAFKA_BROKER_ID: 1
          KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
          KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
          KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
          KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
          KAFKA_JMX_PORT: 9999
          KAFKA_JMX_HOSTNAME: ${DOCKER_HOST_IP:-127.0.0.1}
          KAFKA_AUTHORIZER_CLASS_NAME: kafka.security.authorizer.AclAuthorizer
          KAFKA_ALLOW_EVERYONE_IF_NO_ACL_FOUND: "true"
        depends_on:
          - zoo1
      kafka-ui:
        container_name: kafka-ui
        image: provectuslabs/kafka-ui:latest
        extra_hosts:  # ğŸ‘ˆ æ·»åŠ æ­¤é…ç½®
          - "host.docker.internal:host-gateway" // é¿å…è®¿é—®ä¸åˆ°,éœ€è¦æ·»åŠ 
        ports:
          - 8080:8080
        depends_on:
          - kafka1
        environment:
          DYNAMIC_CONFIG_ENABLED: "TRUE"
    
    docker-compose up -d
    
    // 127.0.0.1:8080 
    ```
    
2. æ·»åŠ é…ç½®
    1. cluster nameï¼šéƒ½å¯ä»¥
    2. bootstrap servers ï¼š host.docker.internal 29092
    3. validateâ†’ok0>submit

### cancal&kafka&go

1. **å®‰è£…kafka-go**
    
    ```go
    go get github.com/segmentio/kafka-go
    ```
    
2. **Canal Kafka**
    
    ```go
    vi canal-server/conf/example/instance.properties
    
    canal.mq.dynamicTopic=mytest,.*,mytest.user,mytest\\..*,.*\\..* // æŒ‰éœ€è¦ä¿®æ”¹
    ä¾‹å¦‚ï¼š
    topic3:commit\\..* //commitæ˜¯æ•°æ®åº“
    ```
    
    ä¿®æ”¹canalé…ç½®æ–‡ä»¶
    
    ```go
    vi /home/admin/canal-server/conf/canal.properties
    
    # å¯é€‰é¡¹: tcp(é»˜è®¤), kafka,RocketMQ,rabbitmq,pulsarmq
    canal.serverMode = kafka
    
    ##################################################
    #########                    Kafka                   #############
    ##################################################
    # æ­¤å¤„é…ç½®ä¿®æ”¹ä¸ºä½ çš„Kafkaç¯å¢ƒåœ°å€
    kafka.bootstrap.servers = 127.0.0.1:9092
    ```
    

## Elasticsearch

Elasticsearch æ˜¯ä¸€ä¸ªé«˜åº¦å¯æ‰©å±•çš„å¼€æºå®æ—¶æœç´¢å’Œåˆ†æå¼•æ“ï¼Œå®ƒå…è®¸ç”¨æˆ·åœ¨è¿‘å®æ—¶çš„æ—¶é—´å†…æ‰§è¡Œå…¨æ–‡æœç´¢ã€ç»“æ„åŒ–æœç´¢ã€èšåˆã€è¿‡æ»¤ç­‰åŠŸèƒ½ã€‚Elasticsearch åŸºäº Lucene æ„å»ºï¼Œæä¾›äº†å¼ºå¤§çš„å…¨æ–‡æœç´¢åŠŸèƒ½ï¼Œå¹¶ä¸”å…·æœ‰å¹¿æ³›çš„åº”ç”¨é¢†åŸŸï¼ŒåŒ…æ‹¬æ—¥å¿—å’Œå®æ—¶åˆ†æã€ç¤¾äº¤åª’ä½“ã€ç”µå­å•†åŠ¡ç­‰ã€‚

Elasticsearch ä¸ºæ‰€æœ‰ç±»å‹çš„æ•°æ®æä¾›è¿‘ä¹å®æ—¶çš„æœç´¢å’Œåˆ†æã€‚æ— è®ºæ˜¯ç»“æ„åŒ–æ–‡æœ¬è¿˜æ˜¯éç»“æ„åŒ–æ–‡æœ¬ã€æ•°å­—æ•°æ®æˆ–åœ°ç†ç©ºé—´æ•°æ®ï¼ŒElasticsearch éƒ½èƒ½å¤Ÿä»¥æ”¯æŒå¿«é€Ÿæœç´¢çš„æ–¹å¼æœ‰æ•ˆåœ°å­˜å‚¨å’Œç´¢å¼•å®ƒä»¬ã€‚é™¤äº†ç®€å•çš„æ•°æ®æ£€ç´¢å’Œèšåˆä¿¡æ¯ä¹‹å¤–ï¼Œè¿˜å¯ä»¥ç”¨ Elasticsearch å‘ç°æ•°æ®ä¸­çš„è¶‹åŠ¿å’Œæ¨¡å¼ã€‚éšç€æ•°æ®å’ŒæŸ¥è¯¢é‡çš„å¢é•¿ï¼ŒElasticsearch çš„åˆ†å¸ƒå¼ç‰¹æ€§èƒ½å¤Ÿæ¨ªå‘æ‰©å±•è‡³æ•°ä»¥ç™¾è®¡çš„æœåŠ¡å™¨å­˜å‚¨ä»¥åŠå¤„ç†PBçº§çš„æ•°æ®ï¼ŒåŒæ—¶å¯ä»¥åœ¨æçŸ­çš„æ—¶é—´å†…ç´¢å¼•ã€æœç´¢å’Œåˆ†æå¤§é‡çš„æ•°æ®ã€‚

- ä¸ºAPPæˆ–ç½‘ç«™å¢åŠ æœç´¢åŠŸèƒ½
- å­˜å‚¨å’Œåˆ†ææ—¥å¿—ã€æŒ‡æ ‡å’Œå®‰å…¨äº‹ä»¶æ•°æ®
- ä½¿ç”¨æœºå™¨å­¦ä¹ å®æ—¶è‡ªåŠ¨å»ºæ¨¡æ•°æ®çš„è¡Œä¸º
- ä½¿ç”¨Elasticsearchä½œä¸ºå­˜å‚¨å¼•æ“è‡ªåŠ¨åŒ–ä¸šåŠ¡å·¥ä½œæµ
- ä½¿ç”¨Elasticsearchä½œä¸ºåœ°ç†ä¿¡æ¯ç³»ç»Ÿï¼ˆGISï¼‰ç®¡ç†ã€é›†æˆå’Œåˆ†æç©ºé—´ä¿¡æ¯
- ä½¿ç”¨Elasticsearchä½œä¸ºç”Ÿç‰©ä¿¡æ¯å­¦ç ”ç©¶å·¥å…·å­˜å‚¨å’Œå¤„ç†é—ä¼ æ•°æ®

Elasticsearch æ¶æ„ä¸»è¦ç”±ä¸‰ä¸ªç»„ä»¶æ„æˆï¼šç´¢å¼•ã€åˆ†ç‰‡å’ŒèŠ‚ç‚¹ã€‚

- ç´¢å¼•æ˜¯æ–‡æ¡£çš„é€»è¾‘åˆ†ç»„ï¼Œç±»ä¼¼äºæ•°æ®åº“ä¸­çš„è¡¨ï¼›
- åˆ†ç‰‡æ˜¯ç´¢å¼•çš„ç‰©ç†åˆ†åŒºï¼Œç”¨äºæé«˜æ•°æ®åˆ†å¸ƒå’ŒæŸ¥è¯¢æ€§èƒ½ï¼›
- èŠ‚ç‚¹æ˜¯è¿è¡Œ Elasticsearch çš„æœåŠ¡å™¨å®ä¾‹ã€‚

Elasticsearch é€šè¿‡ä»¥ä¸‹æ­¥éª¤å®Œæˆæœç´¢å’Œåˆ†æä»»åŠ¡ï¼š

1. æ¥æ”¶ç”¨æˆ·æŸ¥è¯¢è¯·æ±‚ï¼šElasticsearch é€šè¿‡ RESTful API æˆ– JSON è¯·æ±‚æ¥æ”¶ç”¨æˆ·çš„æŸ¥è¯¢è¯·æ±‚ã€‚
2. è·¯ç”±è¯·æ±‚ï¼šæ¥æ”¶åˆ°æŸ¥è¯¢è¯·æ±‚åï¼ŒElasticsearch æ ¹æ®è¯·æ±‚ä¸­çš„ç´¢å¼•å’Œåˆ†ç‰‡ä¿¡æ¯å°†è¯·æ±‚è·¯ç”±åˆ°ç›¸åº”çš„èŠ‚ç‚¹ã€‚
3. æ‰§è¡ŒæŸ¥è¯¢ï¼šèŠ‚ç‚¹æ‰§è¡ŒæŸ¥è¯¢è¯·æ±‚ï¼Œå¹¶åœ¨ç›¸åº”çš„ç´¢å¼•ä¸­æŸ¥æ‰¾åŒ¹é…çš„æ–‡æ¡£ã€‚
4. è¿”å›ç»“æœï¼šæŸ¥è¯¢ç»“æœä»¥ JSON æ ¼å¼è¿”å›ç»™ç”¨æˆ·ï¼ŒåŒ…æ‹¬åŒ¹é…çš„æ–‡æ¡£å’Œç›¸å…³å­—æ®µä¿¡æ¯ã€‚

ç´¢å¼•ï¼ˆIndexï¼‰

åœ¨Elasticsearchä¸­ï¼Œç´¢å¼•æ˜¯å­˜å‚¨ç›¸å…³æ•°æ®çš„æ•°æ®ç»“æ„ï¼Œå¯ä»¥ç†è§£ä¸ºæ•°æ®åº“ä¸­çš„è¡¨ã€‚ç´¢å¼•æ˜¯é€šè¿‡å¯¹æ•°æ®æºè¿›è¡Œç´¢å¼•åˆ›å»ºçš„ï¼Œå®ƒæ˜¯ä¸€ç§å¯¹æ•°æ®è¿›è¡Œç»“æ„åŒ–å’ŒåŠç»“æ„åŒ–å¤„ç†çš„ç»“æœã€‚æ¯ä¸ªç´¢å¼•éƒ½æœ‰è‡ªå·±çš„æ˜ å°„ï¼ˆmappingï¼‰ï¼Œç”¨äºå®šä¹‰æ¯ä¸ªå­—æ®µçš„æ•°æ®ç±»å‹å’Œå…¶ä»–å±æ€§ã€‚

åœ¨Elasticsearchä¸­ï¼Œç´¢å¼•çš„åˆ›å»ºå’Œå®šä¹‰é€šå¸¸æ˜¯é€šè¿‡REST APIæˆ–è€…ç›¸å…³Java APIæ¥å®ç°çš„ã€‚åœ¨åˆ›å»ºç´¢å¼•æ—¶ï¼Œæˆ‘ä»¬éœ€è¦æŒ‡å®šä¸€äº›å‚æ•°ï¼Œæ¯”å¦‚åˆ†ç‰‡æ•°é‡å’Œå‰¯æœ¬æ•°é‡ã€‚åˆ†ç‰‡æ˜¯å°†ç´¢å¼•æ•°æ®æ°´å¹³åˆ‡åˆ†ä¸ºå¤šä¸ªå°å—çš„è¿‡ç¨‹ï¼Œè¿™æ ·å¯ä»¥æé«˜æ•°æ®æ£€ç´¢å’Œå¤„ç†çš„æ•ˆç‡ã€‚å‰¯æœ¬åˆ™æ˜¯å°†ç´¢å¼•æ•°æ®å¤åˆ¶åˆ°ä¸€ä¸ªæˆ–å¤šä¸ªèŠ‚ç‚¹ä¸Šï¼Œä»¥æé«˜æ•°æ®çš„å¯é æ€§å’ŒæŸ¥è¯¢çš„å¯ç”¨æ€§ã€‚

ç´¢å¼•çš„æ˜ å°„ï¼ˆmappingï¼‰æ˜¯ç”¨äºå®šä¹‰ç´¢å¼•ä¸­æ¯ä¸ªå­—æ®µçš„æ•°æ®ç±»å‹å’Œå…¶ä»–å±æ€§ã€‚åœ¨åˆ›å»ºç´¢å¼•æ—¶ï¼Œéœ€è¦å®šä¹‰æ¯ä¸ªå­—æ®µçš„æ•°æ®ç±»å‹ï¼ˆå¦‚æ–‡æœ¬ã€æ•°å­—ã€æ—¥æœŸç­‰ï¼‰å’Œå…¶ä»–å±æ€§ï¼ˆå¦‚æ˜¯å¦éœ€è¦åˆ†æã€æ˜¯å¦å­˜å‚¨ç­‰ï¼‰ã€‚æ­¤å¤–ï¼Œæ˜ å°„è¿˜å¯ä»¥å®šä¹‰å…¶ä»–é«˜çº§åŠŸèƒ½ï¼Œå¦‚èšåˆã€æ’åºå’Œè¿‡æ»¤ç­‰ã€‚

**æ–‡æ¡£ï¼ˆDocumentï¼‰**

æ–‡æ¡£æ˜¯Elasticsearchä¸­å­˜å‚¨å’Œæ£€ç´¢çš„åŸºæœ¬å•ä½ï¼Œå®ƒæ˜¯åºåˆ—åŒ–ä¸ºJSONæ ¼å¼çš„æ•°æ®ç»“æ„ã€‚æ¯ä¸ªæ–‡æ¡£éƒ½æœ‰ä¸€ä¸ªå”¯ä¸€çš„æ ‡è¯†ç¬¦ï¼Œç§°ä¸º_idå­—æ®µï¼Œç”¨äºå”¯ä¸€æ ‡è¯†è¯¥æ–‡æ¡£ã€‚æ¯ä¸ªæ–‡æ¡£éƒ½å­˜å‚¨åœ¨ä¸€ä¸ªç´¢å¼•ä¸­ï¼Œå¹¶ä¸”å¯ä»¥åŒ…å«å¤šä¸ªå­—æ®µï¼Œè¿™äº›å­—æ®µå¯ä»¥æ˜¯ä¸åŒçš„æ•°æ®ç±»å‹ï¼Œå¦‚æ–‡æœ¬ã€æ•°å­—ã€æ—¥æœŸç­‰ã€‚

åœ¨Elasticsearchä¸­ï¼Œæ–‡æ¡£çš„å±æ€§åŒ…æ‹¬_indexã€_typeå’Œ_sourceç­‰ã€‚_indexè¡¨ç¤ºæ–‡æ¡£æ‰€å±çš„ç´¢å¼•åç§°ï¼Œ_typeè¡¨ç¤ºæ–‡æ¡£æ‰€å±çš„ç±»å‹åç§°ï¼ˆåœ¨æ—©æœŸçš„Elasticsearchç‰ˆæœ¬ä¸­ï¼Œè¿™æ˜¯å¿…éœ€çš„ï¼Œä½†åœ¨7.xç‰ˆæœ¬ä¹‹åå·²ç»ä¸å†éœ€è¦ï¼‰ï¼Œ_sourceè¡¨ç¤ºæ–‡æ¡£çš„åŸå§‹JSONæ•°æ®ã€‚

å½“æˆ‘ä»¬åœ¨Elasticsearchä¸­æ‰§è¡Œæœç´¢æŸ¥è¯¢æ—¶ï¼Œå®é™…ä¸Šæ˜¯åœ¨æŸ¥è¯¢æ–‡æ¡£ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ç®€å•çš„å…³é”®å­—æœç´¢ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨å¤æ‚çš„æŸ¥è¯¢è¯­å¥æ¥æœç´¢å¤šä¸ªå­—æ®µã€‚åœ¨æœç´¢æ—¶ï¼ŒElasticsearchä¼šä½¿ç”¨åå‘ç´¢å¼•æ¥å¿«é€Ÿå®šä½åŒ¹é…çš„æ–‡æ¡£ã€‚åå‘ç´¢å¼•æ˜¯ä¸€ä¸ªä¸ºæ¯ä¸ªå­—æ®µå»ºç«‹çš„å€’æ’ç´¢å¼•ï¼Œå®ƒå…è®¸Elasticsearchæ ¹æ®å…³é”®è¯åœ¨å­—æ®µä¸­å¿«é€ŸæŸ¥æ‰¾åŒ…å«è¯¥å…³é”®è¯çš„æ–‡æ¡£ã€‚

**é›†ç¾¤ï¼ˆClusterï¼‰**

ä¸€ä¸ªElasticsearché›†ç¾¤é€šå¸¸åŒ…å«äº†å¤šä¸ªèŠ‚ç‚¹ï¼ˆNodeï¼‰å’Œä¸€ä¸ªæˆ–å¤šä¸ªç´¢å¼•ï¼ˆIndexï¼‰ï¼Œå¹¶ä¸”è¿™äº›èŠ‚ç‚¹å’Œç´¢å¼•å…±åŒæ„æˆäº†æ•´ä¸ªElasticsearché›†ç¾¤ï¼Œåœ¨æ‰€æœ‰èŠ‚ç‚¹ä¸Šæä¾›è”åˆç´¢å¼•å’Œæœç´¢åŠŸèƒ½ã€‚

æ¯ä¸ªClusteréƒ½æœ‰ä¸€ä¸ªå”¯ä¸€çš„åç§°ï¼Œå³cluster nameï¼Œå®ƒç”¨äºæ ‡è¯†å’ŒåŒºåˆ†ä¸åŒçš„Elasticsearché›†ç¾¤ã€‚

**èŠ‚ç‚¹ï¼ˆNodeï¼‰**

åœ¨Elasticsearché›†ç¾¤ä¸­ï¼ŒNodeæ˜¯æŒ‡è¿è¡ŒElasticsearchå®ä¾‹çš„æœåŠ¡å™¨ã€‚æ¯ä¸ªNodeéƒ½æœ‰è‡ªå·±çš„åç§°å’Œæ ‡è¯†ç¬¦ï¼Œå¹¶ä¸”éƒ½æœ‰è‡ªå·±çš„æ•°æ®å­˜å‚¨å’Œç´¢å¼•å­˜å‚¨ã€‚

ä¸€ä¸ªElasticsearché›†ç¾¤ç”±ä¸€ä¸ªæˆ–å¤šä¸ªNodeç»„æˆï¼Œè¿™äº›Nodeé€šè¿‡å®ƒä»¬çš„é›†ç¾¤åç§°è¿›è¡Œæ ‡è¯†ã€‚åœ¨é»˜è®¤æƒ…å†µä¸‹ï¼Œå¦‚æœElasticsearchå·²ç»å¼€å§‹è¿è¡Œï¼Œå®ƒä¼šè‡ªåŠ¨ç”Ÿæˆä¸€ä¸ªå«åšâ€œelasticsearchâ€çš„é›†ç¾¤ã€‚æˆ‘ä»¬ä¹Ÿå¯ä»¥åœ¨é…ç½®æ–‡ä»¶ï¼ˆelasticsearch.ymlï¼‰ä¸­å®šåˆ¶æˆ‘ä»¬çš„é›†ç¾¤åå­—ã€‚

Nodeåœ¨Elasticsearchä¸­æ‰®æ¼”ç€ä¸åŒçš„è§’è‰²ã€‚æ ¹æ®èŠ‚ç‚¹çš„é…ç½®å’ŒåŠŸèƒ½ï¼Œå¯ä»¥å°†Nodeåˆ†ä¸ºä»¥ä¸‹å‡ ç§ç±»å‹ï¼š

- Master Nodeï¼šè´Ÿè´£æ•´ä¸ªClusterçš„é…ç½®å’Œç®¡ç†ä»»åŠ¡ï¼Œå¦‚åˆ›å»ºã€æ›´æ–°å’Œåˆ é™¤ç´¢å¼•ï¼Œæ·»åŠ æˆ–åˆ é™¤Nodeç­‰ã€‚ä¸€ä¸ªClusterä¸­è‡³å°‘éœ€è¦æœ‰ä¸€ä¸ªMaster Nodeã€‚
- Data Nodeï¼šä¸»è¦è´Ÿè´£æ•°æ®çš„å­˜å‚¨å’Œå¤„ç†ï¼Œå®ƒä»¬å¯ä»¥å¤„ç†æ•°æ®çš„CRUDæ“ä½œã€æœç´¢æ“ä½œã€èšåˆæ“ä½œç­‰ã€‚ä¸€ä¸ªClusterä¸­å¯ä»¥æœ‰å¤šä¸ªData Nodeã€‚
- Ingest Nodeï¼šä¸»è¦è´Ÿè´£å¯¹æ–‡æ¡£è¿›è¡Œé¢„å¤„ç†ï¼Œå¦‚è§£æã€è½¬æ¢ã€è¿‡æ»¤ç­‰æ“ä½œï¼Œç„¶åå†å°†æ–‡æ¡£å†™å…¥åˆ°Indexä¸­ã€‚æ¯ä¸ªClusterä¸­è‡³å°‘éœ€è¦æœ‰ä¸€ä¸ªIngest Nodeã€‚ é™¤äº†ä¸Šè¿°çš„ä¸‰ç§ç±»å‹å¤–ï¼Œè¿˜å¯ä»¥æœ‰Tribe Nodeã€Remote Cluster Clientç­‰ç‰¹æ®Šç”¨é€”çš„Nodeã€‚

Nodeä¹‹é—´æ˜¯å¯¹ç­‰å…³ç³»ï¼ˆå»ä¸­å¿ƒåŒ–ï¼‰ï¼Œæ¯ä¸ªèŠ‚ç‚¹ä¸Šé¢çš„é›†ç¾¤çŠ¶æ€æ•°æ®éƒ½æ˜¯å®æ—¶åŒæ­¥çš„ã€‚å¦‚æœMasterèŠ‚ç‚¹å‡ºæ•…éšœï¼ŒæŒ‰ç…§é¢„å®šçš„ç¨‹åºï¼Œå…¶ä»–ä¸€å°Nodeæœºå™¨ä¼šè¢«é€‰ä¸¾æˆä¸ºæ–°çš„Masterã€‚

éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œä¸€ä¸ªNodeå¯ä»¥åŒæ—¶æ‹¥æœ‰ä¸€ç§æˆ–å‡ ç§åŠŸèƒ½ï¼Œå¦‚ä¸€ä¸ªNodeå¯ä»¥åŒæ—¶æ˜¯Master Nodeå’ŒData Nodeã€‚

**åˆ†ç‰‡ï¼ˆShardsï¼‰**

åœ¨Elasticsearchä¸­ï¼ŒShardsæ˜¯ç´¢å¼•çš„åˆ†ç‰‡ï¼Œæ¯ä¸ªShardéƒ½æ˜¯ä¸€ä¸ªåŸºäºLuceneçš„ç´¢å¼•ã€‚å½“ç´¢å¼•çš„æ•°æ®é‡å¤ªå¤§æ—¶ï¼Œç”±äºå†…å­˜çš„é™åˆ¶ã€ç£ç›˜å¤„ç†èƒ½åŠ›ä¸è¶³ã€æ— æ³•è¶³å¤Ÿå¿«çš„å“åº”å®¢æˆ·ç«¯çš„è¯·æ±‚ç­‰ï¼Œä¸€ä¸ªèŠ‚ç‚¹å¯èƒ½ä¸å¤Ÿç”¨ã€‚è¿™ç§æƒ…å†µä¸‹ï¼Œæ•°æ®å¯ä»¥è¢«åˆ†ä¸ºè¾ƒå°çš„åˆ†ç‰‡ï¼Œæ¯ä¸ªåˆ†ç‰‡æ”¾åˆ°ä¸åŒçš„æœåŠ¡å™¨ä¸Šã€‚æ¯ä¸ªåˆ†ç‰‡å¯ä»¥æœ‰é›¶ä¸ªæˆ–å¤šä¸ªå‰¯æœ¬ã€‚è¿™ä¸ä»…èƒ½å¤Ÿæé«˜æŸ¥è¯¢æ•ˆç‡ï¼Œè¿˜èƒ½å¤Ÿæé«˜ç³»ç»Ÿçš„å¯é æ€§å’Œå¯ç”¨æ€§ã€‚å¦‚æœæŸä¸ªèŠ‚ç‚¹æˆ–Shardå‘ç”Ÿæ•…éšœï¼ŒElasticsearchå¯ä»¥ä»å…¶ä»–èŠ‚ç‚¹æˆ–Shardçš„å‰¯æœ¬ä¸­æ¢å¤æ•°æ®ï¼Œä»è€Œä¿è¯æ•°æ®çš„å¯é æ€§å’Œå¯ç”¨æ€§ã€‚

æ¯ä¸ªShardéƒ½å­˜å‚¨åœ¨é›†ç¾¤ä¸­çš„æŸä¸ªèŠ‚ç‚¹ä¸Šï¼Œæ¯ä¸ªèŠ‚ç‚¹å¯ä»¥å­˜å‚¨ä¸€ä¸ªæˆ–å¤šä¸ªShardã€‚å½“æŸ¥è¯¢ä¸€ä¸ªç´¢å¼•æ—¶ï¼ŒElasticsearchä¼šåœ¨æ‰€æœ‰çš„Shardä¸Šæ‰§è¡ŒæŸ¥è¯¢ï¼Œå¹¶å°†ç»“æœåˆå¹¶è¿”å›ç»™ç”¨æˆ·ã€‚

å¯¹äºæ¯ä¸ªç´¢å¼•ï¼Œåœ¨åˆ›å»ºæ—¶éœ€è¦æŒ‡å®šä¸»åˆ†ç‰‡çš„æ•°é‡ï¼Œä¸€æ—¦ç´¢å¼•åˆ›å»ºåï¼Œä¸»åˆ†ç‰‡çš„æ•°é‡å°±ä¸èƒ½æ›´æ”¹ã€‚

**å‰¯æœ¬ï¼ˆReplicasï¼‰**

åœ¨Elasticsearchä¸­ï¼ŒReplicasæ˜¯æŒ‡ç´¢å¼•çš„å‰¯æœ¬ã€‚å®ƒä»¬çš„ä½œç”¨ä¸»è¦æœ‰ä¸¤ç‚¹ï¼š

- æé«˜ç³»ç»Ÿçš„å®¹é”™æ€§ã€‚å½“æŸä¸ªèŠ‚ç‚¹å‘ç”Ÿæ•…éšœï¼Œæˆ–è€…æŸä¸ªåˆ†ç‰‡ï¼ˆShardï¼‰æŸåæˆ–ä¸¢å¤±æ—¶ï¼Œå¯ä»¥ä»å‰¯æœ¬ä¸­æ¢å¤æ•°æ®ã€‚è¿™æ„å‘³ç€ï¼Œå³ä½¿ä¸€ä¸ªèŠ‚ç‚¹æˆ–åˆ†ç‰‡å‡ºç°é—®é¢˜ï¼Œä¹Ÿä¸ä¼šå¯¼è‡´æ•´ä¸ªç´¢å¼•çš„æ•°æ®ä¸¢å¤±ã€‚è¿™ç§æœºåˆ¶å¯ä»¥å¢åŠ ç³»ç»Ÿçš„å¯é æ€§ï¼Œå¹¶å‡å°‘å› èŠ‚ç‚¹æˆ–åˆ†ç‰‡æ•…éšœå¯¼è‡´çš„å®•æœºæ—¶é—´ã€‚
- æé«˜æŸ¥è¯¢æ•ˆç‡ã€‚Elasticsearchä¼šè‡ªåŠ¨å¯¹æœç´¢è¯·æ±‚è¿›è¡Œè´Ÿè½½å‡è¡¡ï¼Œå¯ä»¥å°†æœç´¢è¯·æ±‚åˆ†é…åˆ°å¤šä¸ªèŠ‚ç‚¹ä¸Šï¼Œä»è€Œå¹¶è¡Œå¤„ç†æœç´¢è¯·æ±‚ï¼Œæé«˜æŸ¥è¯¢æ•ˆç‡ã€‚è¿™ç§è´Ÿè½½å‡è¡¡æœºåˆ¶å¯ä»¥åœ¨èŠ‚ç‚¹ä¹‹é—´åˆ†å‘æŸ¥è¯¢è¯·æ±‚ï¼Œä½¿å¾—æ¯ä¸ªèŠ‚ç‚¹éƒ½å¯ä»¥å¤„ç†ä¸€éƒ¨åˆ†æŸ¥è¯¢è¯·æ±‚ï¼Œä»è€Œé¿å…äº†ä¸€ä¸ªèŠ‚ç‚¹çš„ç“¶é¢ˆæ•ˆåº”ã€‚

éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œåœ¨Elasticsearchä¸­ï¼Œæ¯ä¸ªç´¢å¼•å¯ä»¥æœ‰å¤šä¸ªå‰¯æœ¬ï¼ˆReplicasï¼‰ï¼Œä½†æ˜¯æ¯ä¸ªå‰¯æœ¬åªèƒ½æœ‰ä¸€ä¸ªä¸»åˆ†ç‰‡ï¼ˆPrimary Shardï¼‰ã€‚å¯ä»¥å¢åŠ æˆ–åˆ é™¤å‰¯æœ¬çš„æ•°é‡ã€‚

| ESæ¦‚å¿µ | å…³ç³»å‹æ•°æ®åº“ |
| --- | --- |
| Indexï¼ˆç´¢å¼•ï¼‰æ”¯æŒå…¨æ–‡æ£€ç´¢ | Tableï¼ˆè¡¨ï¼‰ |
| Documentï¼ˆæ–‡æ¡£ï¼‰ï¼Œä¸åŒæ–‡æ¡£å¯ä»¥æœ‰ä¸åŒçš„å­—æ®µé›†åˆ | Rowï¼ˆæ•°æ®è¡Œï¼‰ |
| Fieldï¼ˆå­—æ®µï¼‰ | Columnï¼ˆæ•°æ®åˆ—ï¼‰ |
| Mappingï¼ˆæ˜ å°„ï¼‰ | Schemaï¼ˆæ¨¡å¼ï¼‰ |
1. **æ­å»ºElasticsearchç¯å¢ƒ**

ä½¿ç”¨docker compose å¿«é€Ÿæ­å»ºä¸€å¥—Elasticsearchå’ŒKibanaç¯å¢ƒã€‚

Kibana æä¾›äº†ä¸€ä¸ªå¥½ç”¨çš„å¼€å‘è€…æ§åˆ¶å°ï¼Œéå¸¸é€‚åˆç”¨æ¥ç»ƒä¹ Elasticsearchå‘½ä»¤ã€‚

```go
services:
  elasticsearch:
    container_name: elasticsearch
    image: docker.elastic.co/elasticsearch/elasticsearch:8.9.1
    environment:
      - node.name=elasticsearch
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
      - discovery.type=single-node
      - xpack.security.enabled=false
    ports:
      - 9200:9200
      - 9300:9300
    networks:
      - elastic
  kibana:
    image: docker.elastic.co/kibana/kibana:8.9.1
    container_name: kibana
    ports:
      - 5601:5601
    networks:
      - elastic
    depends_on:
      - elasticsearch

networks:
  elastic:

--> docker-compose up
--> http://127.0.0.1:5601
--> Explore on my own
Dev Tools
```

## go-kafka-elasticsearch

1. kafka è®°è½½sqlçš„å˜åŒ–
2. ä»kafakä¸­è¯»å–åˆ°esä¸­å¹¶åˆ›å»ºæˆ–æ›´æ–°

æ•°æ®æµå‘ï¼šmysqlâ†’kafkaâ†’elasticsearch

```go
type JobWork struct {
	kafkaReader *kafka.Reader
	esClient *EsClient
	log *log.Helper
}
```

1. é…ç½®kafakå’Œes

```go
func NewKafkaReader(conf *conf.Kafka) *kafka.Reader {
	return kafka.NewReader(kafka.ReaderConfig{
		Brokers:   conf.Brokers,
		Topic:     conf.Topic,
		GroupID: conf.GroupId,
	})
}

type EsClient struct{
	*elasticsearch.TypedClient
	index string
}

func NewESClient(cfg *conf.Elasticsearch) (*EsClient, error) {
	// ES é…ç½®
	c := elasticsearch.Config{
		Addresses: cfg.Addresses,
	}

	// åˆ›å»ºå®¢æˆ·ç«¯è¿æ¥
	client, err := elasticsearch.NewTypedClient(c)
	if err != nil {
		return nil, err
	}
	return &EsClient{
		TypedClient: client,
		index:       cfg.Index,
	}, nil
}
```

1. è¦æ³¨å†Œåˆ°æœåŠ¡

```go
return kratos.New->kratos.Server

type Server interface {
	Start(context.Context) error
	Stop(context.Context) error
}

// å®ç°
func (jw JobWork) Start(ctx context.Context) error {
	jw.log.Debug("JobWorker start....")
	// 1. ä»kafkaä¸­è·å–MySQLä¸­çš„æ•°æ®å˜æ›´æ¶ˆæ¯
	// æ¥æ”¶æ¶ˆæ¯
	for {
		m, err := jw.kafkaReader.ReadMessage(ctx)
		if errors.Is(err, context.Canceled){
			return nil
		}
		if err != nil {
			jw.log.Errorf("read message failed:%v\n", err)
			break 
		}
		jw.log.Debugf("message at offset %d: %s = %s\n", m.Offset, string(m.Key), string(m.Value))

		// 2.å°†å®Œæ•´æ•°æ®å†™å…¥ES
		msg := new(Msg)
		if err := json.Unmarshal(m.Value, msg); err != nil{
			jw.log.Errorf("unmarshal msg from kafka failed, err:%v", err)
			continue
		}
		if msg.Type == "INSERT" {
			// å¾€ESä¸­æ–°å¢æ–‡æ¡£
			for idx := range msg.Data {
				jw.indexDocument(msg.Data[idx])
			}
		} else {
			// å¾€ESä¸­æ›´æ–°æ–‡æ¡£
			for idx := range msg.Data {
				jw.updateDocument(msg.Data[idx])
			}
		}
	}
	return nil
}

func (jw JobWork) Stop(ctx context.Context) error {
	jw.log.Debug("JobWorker stop....")
	// ç¨‹åºé€€å‡ºå‰å…³é—­Reader
	return jw.kafkaReader.Close()
}
```

1. æ¶ˆæ¯ä½“

```go
type Msg struct{
	Type     string `json:"type"`
	Database string `json:"databse"`
	Table    string `json:"table"`
	IsDdl    bool   `json:"isDdl"`
	Data     []map[string]interface{}
}
```

1. esæ“ä½œ

```go
// indexDocument ç´¢å¼•æ–‡æ¡£
func (jw JobWork) indexDocument(d map[string]interface{}) {
	reviewID := d["review_id"].(string)
	// æ·»åŠ æ–‡æ¡£
	resp, err := jw.esClient.Index(jw.esClient.index).
		Id(reviewID).
		Document(d).
		Do(context.Background())
	if err != nil {
		jw.log.Errorf("indexing document failed, err:%v\n", err)
		return
	}
	jw.log.Debugf("result:%#v\n", resp.Result)
}

// updateDocument æ›´æ–°æ–‡æ¡£
func (jw JobWork) updateDocument(d map[string]interface{}) {
	reviewID := d["review_id"].(string)
	resp, err := jw.esClient.Update(jw.esClient.index, reviewID).
		Doc(d). // ä½¿ç”¨ç»“æ„ä½“å˜é‡æ›´æ–°
		Do(context.Background())
	if err != nil {
		jw.log.Debugf("update document failed, err:%v\n", err)
		return
	}
	jw.log.Debugf("result:%v\n", resp.Result)
}
```

1. ä¾èµ–æ³¨å…¥

```go
// ProviderSet is data providers.
var ProviderSet = wire.NewSet(NewESClient, NewJobWrok, NewKafkaReader)
-->
// wireApp init kratos application.
func wireApp(*conf.Server, *conf.Kafka, *conf.Elasticsearch,  *conf.Data, log.Logger) (*kratos.App, func(), error) {
	panic(wire.Build(server.ProviderSet, data.ProviderSet, biz.ProviderSet, service.ProviderSet, job.ProviderSet, newApp))
}

-->
func newApp(logger log.Logger, gs *grpc.Server, hs *http.Server, js *job.JobWork)
-->
app, cleanup, err := wireApp(bc.Server, bc.Kafka, bc.Elasticsearch, bc.Data, logger)
```

ä»esä¸­è¯»å–æ•°æ®

1. é…ç½®æ–‡ä»¶ï¼Œè¿™é‡Œä»¥é€šè¿‡store_idè·å–ä¿¡æ¯
    
    ```go
    // æ ¹æ®å•†å®¶idæŸ¥è¯¢è¯„ä»·åˆ—è¡¨ï¼ˆåˆ†é¡µï¼‰
    	rpc ListReviewByStoreID(ListReviewByStoreIDRequest) returns (ListReviewByStoreIDResponse){}
    	
    	message ListReviewByStoreIDRequest {
    	int64 storeID = 1 [(validate.rules).int64 = {gt: 0}];
    	int32 page = 2 [(validate.rules).int32 = {gt: 0}];
    	int32 size = 3 [(validate.rules).int32 = {gt: 0}];
    }
    
    message ListReviewByStoreIDResponse{
    	repeated ReviewInfo list = 1;
    }
    ```
    
2. ç”Ÿæˆä»£ç ï¼Œä¸šåŠ¡é€»è¾‘
    1. service
        1. è°ƒç”¨bizè·å–ä¿¡æ¯
            
            ```go
            reviewList, err := s.uc.ListReviewByStoreID(ctx, req.StoreID, req.Page, req.Size)
            	if err != nil{
            		return nil, err
            	}
            ```
            
        2. æ ¼å¼åŒ–
            
            ```go
            list := make([]*pb.ReviewInfo, 0, len(reviewList))
            	for _, r := range reviewList {
            		list = append(list, &pb.ReviewInfo{
            			ReviewID: r.ReviewID,
            			UserID: r.UserID,
            			OrderID: r.OrderID,
            			Score: r.Score,
            			ServiceScore: r.ServiceScore,
            			ExpressScore: r.ExpressScore,
            			Content: r.Content,
            			PicInfo: r.PicInfo,
            			VideoInfo: r.VideoInfo,
            			Status: r.Status,
            		})
            	}
            ```
            
    2. biz
        1. å¯¹å‚æ•°è¿›è¡Œæ ¡éªŒå’Œåˆå§‹åŒ–page, size, limit
            
            ```go
            if page <= 0{
            		page = 1
            	}
            	if size <= 0 || size > 50{
            		size = 10
            	}
            	offset := (page - 1) * size
            	limit := size
            ```
            
        2. è°ƒç”¨dataå±‚è·å–ä¿¡æ¯
            
            ```go
            uc.log.WithContext(ctx).Debugf("[biz] ListReviewByStoreID storeID:%v\n", storeID)
            ```
            
        3. !!!è¿™é‡Œçš„åˆ›å»ºæ—¶é—´ä¼šæŠ¥é”™ï¼Œæ ¼å¼ä¸ç¬¦åˆgoçš„æ‰€ä»¥é‡æ–°å®šä¹‰
            
            ```go
            type MyReviewinfo struct{
            	*model.ReviewInfo
            	CreateAt     MyTime `json:"create_at"` // åˆ›å»ºæ—¶é—´
            	UpdateAt     MyTime `json:"update_at"` // åˆ›å»ºæ—¶é—´
            	Anonymous    int32  `json:"anonymous,string"`
            	Score        int32  `json:"score,string"`
            	ServiceScore int32  `json:"service_score,string"`
            	ExpressScore int32  `json:"express_score,string"`
            	HasMedia     int32  `json:"has_media,string"`
            	Status       int32  `json:"status,string"`
            	IsDefault    int32  `json:"is_default,string"`
            	HasReply     int32  `json:"has_reply,string"`
            	ID           int64  `json:"id,string"`
            	Version      int32  `json:"version,string"`
            	ReviewID     int64  `json:"review_id,string"`
            	OrderID      int64  `json:"order_id,string"`
            	SkuID        int64  `json:"sku_id,string"`
            	SpuID        int64  `json:"spu_id,string"`
            	StoreID      int64  `json:"store_id,string"`
            	UserID       int64  `json:"user_id,string"`
            }
            
            type MyTime time.Time
            
            // UnmarshalJSON json.Unmarshal çš„æ—¶å€™ä¼šè‡ªåŠ¨è°ƒç”¨è¿™ä¸ªæ–¹æ³•
            func (t *MyTime) UnmarshalJSON(data []byte) error {
            	s := strings.Trim(string(data), `"`)
            	tmp, err := time.Parse(time.DateTime, s)
            	if err != nil{
            		return err
            	}
            	*t = MyTime(tmp)
            	return nil
            }
            ```
            
    3. data
        1. å»esæŸ¥è¯¢
            1. è¿æ¥es
                
                ```go
                type Data struct {
                	query *query.Query
                	log *log.Helper
                	es *elasticsearch.TypedClient
                }
                
                func NewEsclient(cfg *conf.Elasticsearch) (*elasticsearch.TypedClient, error) {
                	// ES é…ç½®
                	c := elasticsearch.Config{
                		Addresses: cfg.GetAddresses(),
                	}
                	// åˆ›å»ºå®¢æˆ·ç«¯
                	return elasticsearch.NewTypedClient(c)
                }
                
                // ProviderSet is data providers.
                var ProviderSet = wire.NewSet(NewData, NewReviewRepo, NewDB, NewEsclient)
                ```
                
            2. æŸ¥è¯¢
                
                ```go
                resq, err := r.data.es.Search().
                		Index("review").
                		From(int(offset)).
                		Size(int(limit)).
                		Query(&types.Query{
                			Bool: &types.BoolQuery{
                				Filter: []types.Query{
                					{
                						Term: map[string]types.TermQuery{
                							"store_id": {Value: storeID},
                						},
                					},
                				},
                			},
                		}).
                		Do(ctx)
                	if err != nil{
                		return nil, err
                	}
                ```
                
            3. ååºåˆ—åŒ–
                
                ```go
                // è¿”åºåˆ—å
                	list := make([]*biz.MyReviewinfo, 0, resq.Hits.Total.Value)
                
                	for _, hit := range resq.Hits.Hits{
                		tmp := &biz.MyReviewinfo{}
                		if err := json.Unmarshal(hit.Source_, tmp); err != nil{
                			r.log.Errorf("json.Unmarshal(hit.Source_, tmp) failed, err:%v", err)
                			continue
                		}
                		list = append(list, tmp)
                	}
                	return list, nil
                ```
                
    4. cmd ä¾èµ–æ³¨å…¥
        
        ```go
        app, cleanup, err := wireApp(bc.Server, &rc, bc.Data, bc.Elasticsearch, logger)
        
        func wireApp(*conf.Server, *conf.Registry, *conf.Data, *conf.Elasticsearch, log.Logger) (*kratos.App, func(), error) {
        	panic(wire.Build(server.ProviderSet, data.ProviderSet, biz.ProviderSet, service.ProviderSet, newApp))
        }
        ```
        
    5. elasticsearch é…ç½®
        
        ```go
        elasticsearch:
          addresses:
            - "http://127.0.0.1:9200"
            
        message Bootstrap {
          Server server = 1;
          Data data = 2;
          Snowflake snowflake = 3;
          Elasticsearch elasticsearch = 4;
        }
        
        message Elasticsearch{
          repeated string addresses = 1;
        }   
        ```
        

## è®¾ç½®ç¼“å­˜

1. é…ç½®æ–‡ä»¶
    
    ```go
    message Data {
      message Database {
        string driver = 1;
        string source = 2;
      }
      message Redis {
        string network = 1;
        string addr = 2;
        google.protobuf.Duration read_timeout = 3;
        google.protobuf.Duration write_timeout = 4;
      }
      Database database = 1;
      Redis redis = 2;
    }
    
      redis:
        addr: 127.0.0.1:6379
        read_timeout: 0.2s
        write_timeout: 0.2s
    ```
    
2. redisè¿æ¥
    
    ```go
    // NewRedisClient redisè¿æ¥
    func NewRedisClient(cfg *conf.Data) *redis.Client{
    	return redis.NewClient(&redis.Options{
    		Addr: cfg.Redis.Addr,
    		WriteTimeout: cfg.Redis.WriteTimeout.AsDuration(),
    		ReadTimeout: cfg.Redis.ReadTimeout.AsDuration(),
    	})
    }
    
    // ProviderSet is data providers.
    var ProviderSet = wire.NewSet(NewData, NewReviewRepo, NewDB, NewEsclient, NewRedisClient)
    
    // Data .
    type Data struct {
    	query *query.Query
    	log *log.Helper
    	es *elasticsearch.TypedClient
    	rdb *redis.Client
    }
    ```
    
    ä¾èµ–æ³¨å…¥
    
3. ä¸šåŠ¡é€»è¾‘
    1.  é€šè¿‡singleflight åˆå¹¶çŸ­æ—¶é—´å†…å¤§é‡çš„å¹¶å‘æŸ¥è¯¢
        
        ```go
        var g singleflight.Group
        
        // getDataBySingleflight åˆå¹¶çŸ­æ—¶é—´å†…å¤§é‡çš„å¹¶å‘æŸ¥è¯¢
        func (r *reviewRepo) getDataBySingleflight(ctx context.Context, key string)([]byte, error){
        	v, err, shared := g.Do(key, func() (interface{}, error){
        		// æŸ¥ç¼“å­˜
        		data, err := r.getDataFromCache(ctx, key)
        		if err == nil{
        			return data, nil
        		}
        
        		// ç¼“å­˜ä¸­æ²¡æœ‰, åªæœ‰åœ¨ç¼“å­˜ä¸­æ²¡æœ‰è¿™ä¸ªkeyçš„é”™è¯¯æ—¶æ‰æŸ¥ES
        		if errors.Is(err, redis.Nil){
        			// æŸ¥ES
        			data, err := r.getDataFromEs(ctx, key)
        			if err == nil{
        				// è®¾ç½®ç¼“å­˜
        				return data, r.setCache(ctx, key, data)
        			}
        			return nil, err
        		}
        
        		// æŸ¥ç¼“å­˜å¤±è´¥
        		return nil, err
        	})
        	r.log.Debugf("getDataBySingleflight ret: v:%v, err: %v shared:%v\n", v, err, shared)
        	if err != nil {
        		return nil, err
        	}
        	return v.([]byte), nil
        }
        ```
        
    2. å…ˆæŸ¥è¯¢Redisç¼“å­˜
        
        ```go
        // getDataFromCache è¯»å–ç¼“å­˜æ•°æ®
        func  (r *reviewRepo) getDataFromCache(ctx context.Context, key string) ([]byte, error){
        	r.log.Debugf("getDataFromCache key:%v\n", key)
        	return r.data.rdb.Get(ctx, key).Bytes()
        }
        ```
        
    3. å­˜æ²¡æœ‰åˆ™æŸ¥è¯¢ES
        
        ```go
        // getDataFromEs ä»esè¯»å–æ•°æ®
        func (r *reviewRepo) getDataFromEs(ctx context.Context, key string) ([]byte, error){
        	values := strings.Split(key, ":")
        	if len(values) < 4 {
        		return nil, errors.New("invalid key")
        	}
        	index, storeID, offsetStr, limitStr := values[0], values[1],  values[2],  values[3]
        
        	offset, err := strconv.Atoi(offsetStr)
        	if err != nil {
        		return nil, err
        	}
        	limit, err := strconv.Atoi(limitStr)
        	if err != nil {
        		return nil, err
        	}
        
        	resq, err := r.data.es.Search().
        		Index(index).
        		From(offset).
        		Size(limit).
        		Query(&types.Query{
        			Bool: &types.BoolQuery{
        				Filter: []types.Query{
        					{
        						Term: map[string]types.TermQuery{
        							"store_id": {Value: storeID},
        						},
        					},
        				},
        			},
        		}).
        		Do(ctx)
        	if err != nil{
        		return nil, err
        	}
        
        	return json.Marshal(resq.Hits)
        }
        ```
        
    4. è®¾ç½®ç¼“å­˜
        
        ```go
        // setCache è®¾ç½®ç¼“å­˜
        func (r *reviewRepo) setCache(ctx context.Context, key string,  data []byte) error {
        	return r.data.rdb.Set(ctx, key, data, time.Second*10).Err()
        }
        ```
        

## ç”Ÿæˆapiæ–‡æ¡£

kratos æ¡†æ¶â½€æŒâ½£æˆ openapi.yaml â½‚ä»¶ã€‚

1. å®‰è£…â½£æˆopenapiâ½‚ä»¶çš„ protoc æ’ä»¶
    
    ```go
    go install github.com/google/gnostic/cmd/protoc-gen-openapi@latest
    ```
    
2. é¡¹â½¬æ ¹â½¬å½•ä¸‹æ‰§â¾ä»¥ä¸‹å‘½ä»¤æ ¹æ®APIçš„ protoâ½‚ä»¶â½£æˆ openapi.yamlâ½‚ä»¶
    
    ```go
    make api
    ```
    
3. [swagger.io](http://swagger.io/) æä¾›äº†å¼€æºçš„ Swagger Editor ï¼Œç›´æ¥å¯¼â¼Šé¡¹â½¬â½¬å½•ä¸‹çš„ openapi.yaml â½‚ä»¶çš†å¯ã€‚